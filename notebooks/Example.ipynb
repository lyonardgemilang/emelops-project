{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134afe99-e486-443a-b101-0512887b42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import io\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b560db7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tracker_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLFLOW_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m bucket_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGCS_BUCKET_NAME_DATASET\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGOOGLE_APPLICATION_CREDENTIALS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGLE_APPLICATION_CREDENTIALS_NOTEBOOK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m object_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miris.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m \n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/MLOps/lib/python3.10/os.py:685\u001b[0m, in \u001b[0;36m_Environ.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[1;32m    684\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)\n\u001b[0;32m--> 685\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencodevalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m     putenv(key, value)\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/MLOps/lib/python3.10/os.py:757\u001b[0m, in \u001b[0;36m_createenviron.<locals>.encode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(value):\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 757\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr expected, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mencode(encoding, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "instance = os.getenv(\"GOOGLE_CLOUD_INSTANCE\")\n",
    "tracker_url = os.getenv(\"MLFLOW_URL\")\n",
    "bucket_name = os.getenv(\"GCS_BUCKET_NAME_DATASET\")\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS_NOTEBOOK\")\n",
    "object_name = \"iris.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = boto3.client(\n",
    "#     's3',\n",
    "#     endpoint_url=s3_url,\n",
    "#     aws_access_key_id=access_key,\n",
    "#     aws_secret_access_key=secret_key\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36432597",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.get_bucket(bucket_name)\n",
    "blob = bucket.get_blob(object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1113f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully:\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     response = s3.get_object(Bucket=bucket_name, Key=object_name)\n",
    "#     dataset_content = response.get('Body')\n",
    "#     # print(dataset_content)\n",
    "#     # Load the dataset into a DataFrame\n",
    "#     df = pd.read_csv(dataset_content)\n",
    "#     print(\"Dataset loaded successfully:\")\n",
    "#     print(df.head())\n",
    "# except Exception as e:\n",
    "#     print(\"Error fetching dataset from MinIO:\", e)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "        # Open the blob and read its contents\n",
    "        with blob.open(\"r\") as f:\n",
    "                # Use StringIO to treat the blob's content as a file-like object\n",
    "                dataset_content = io.StringIO(f.read())\n",
    "\n",
    "        # Load the dataset content into a DataFrame\n",
    "        df = pd.read_csv(dataset_content)\n",
    "        print(\"Dataset loaded successfully:\")\n",
    "        print(df.head())\n",
    "except Exception as e:\n",
    "        print(\"Error fetching dataset from GCS:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14ffc0c-4350-4487-b7a2-4f13295e1d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 16:44:53 INFO mlflow.tracking.fluent: Experiment with name 'test' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://mlflow.fauzanghaza.com\")\n",
    "experiment_name = \"test\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "data = df.drop('Species', axis=1)\n",
    "target = df['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf32ed02-8ea6-4915-b3f3-350e48707902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 16:45:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/06 16:45:04 INFO mlflow.tracking._tracking_service.client: üèÉ View run charming-wolf-707 at: https://mlflow.fauzanghaza.com/#/experiments/1/runs/23238f4296894f1394e1923df5513cda.\n",
      "2024/11/06 16:45:04 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://mlflow.fauzanghaza.com/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 23238f4296894f1394e1923df5513cda\n",
      "Model accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Define model parameters\n",
    "    n_estimators = 100\n",
    "    max_depth = 5\n",
    "    random_state = 42\n",
    "\n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "    # Train the model\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and calculate accuracy\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log the model artifact to MinIO via MLflow\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Print Run ID for reference\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Model accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
