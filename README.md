# **MLOps Project**

This project is an end-to-end implementation of an MLOps pipeline for machine learning model development, tracking, and deployment. It utilizes **MLflow**, **MinIO**, **FastAPI**, **PostgreSQL**, and Docker to enable efficient experimentation, artifact storage, and model serving.

---

## **Features**

- **MLflow** for experiment tracking, model management, and versioning.
- **MinIO** for scalable, S3-compatible object storage.
- **FastAPI** for serving machine learning models via REST APIs.
- **PostgreSQL** for managing MLflow backend metadata.
- **Docker Compose** for container orchestration.
- **Jupyter Notebook** integration for model development and experimentation.

---

## **Setup Instructions**

### **1. Prerequisites**

Ensure the following tools are installed:

- [Docker](https://docs.docker.com/get-docker/)
- [Make](https://www.gnu.org/software/make/) (Installed by default on macOS/Linux; use `choco install make` on Windows).

---

### **2. Clone the Repository**

Clone the repository to your local system:
```bash
git clone <repository_url>
cd <repository_directory>
```

---

### **3. Environment Configuration**

1. Copy the `.env.example` file to `.env`:
   ```bash
   cp .env.example .env
   ```

2. Update the `.env` file with your configuration:

   #### **MinIO Configuration**
   ```plaintext
   MINIO_ROOT_USER=your_minio_root_user
   MINIO_ROOT_PASSWORD=your_minio_root_password
   AWS_ACCESS_KEY_ID=your_aws_access_key
   AWS_SECRET_ACCESS_KEY=your_aws_secret_key
   S3_URL=https://s3:443
   MLFLOW_BUCKET=your_mlflow_bucket
   DATASET_BUCKET=your_dataset_bucket
   ```

   #### **PostgreSQL Configuration**
   ```plaintext
   POSTGRES_USER=your_postgres_user
   POSTGRES_PASSWORD=your_postgres_password
   POSTGRES_DB=your_postgres_db
   PGADMIN_DEFAULT_EMAIL=your_pgadmin_email
   PGADMIN_DEFAULT_PASSWORD=your_pgadmin_password
   DB_URL=db
   DB_ADMIN_URL=dbadmin
   ```

   #### **MLflow Configuration**
   ```plaintext
   MLFLOW_ADMIN_USERNAME=your_mlflow_admin_username
   MLFLOW_ADMIN_PASSWORD=your_mlflow_admin_password
   MLFLOW_AUTH_CONFIG_PATH=your_mlflow_auth_config_path
   ```

   #### **Client Configuration**
   ```plaintext
   MLFLOW_S3_ENDPOINT_URL_CLIENT=your_mlflow_s3_endpoint_url
   AWS_ACCESS_KEY_ID_CLIENT=your_aws_access_key
   AWS_SECRET_ACCESS_KEY_CLIENT=your_aws_secret_key
   MLFLOW_URL_CLIENT=your_mlflow_url
   MLFLOW_ADMIN_USERNAME_CLIENT=your_mlflow_admin_username
   MLFLOW_ADMIN_PASSWORD_CLIENT=your_mlflow_admin_password
   ```

---

### **4. Run the Project**

Use the `Makefile` for automation:

#### **Start Services**
```bash
sudo make run
```

This will:
- Create necessary networks and containers.
- Build and start services for **MLflow**, **MinIO**, **PostgreSQL**, **FastAPI**, and **pgAdmin**.

---

### **5. Upload Dataset to MinIO**

1. Access the MinIO web interface at [https://localhost:443](https://localhost:443).
2. Log in with the credentials specified in your `.env` file.
3. Create a bucket named `dataset`.
4. Upload your dataset file (e.g., `StressLevelDataset.csv`) to the `dataset` bucket.

---

### **6. Train and Log Models**

Use the provided Jupyter notebook `notebooks/Example.ipynb` for training and logging models to MLflow:

#### **Notebook Steps:**
1. Fetch the dataset from MinIO.
2. Train machine learning models (e.g., **RandomForestClassifier**, **XGBoost**).
3. Log metrics, parameters, and models to MLflow.
4. Access MLflow at [http://localhost:80](http://localhost:80).

---

### **7. Serve the Model**

1. Models logged in MLflow are automatically served via **FastAPI**.
2. Access the FastAPI service at [http://localhost:8000](http://localhost:8000).

#### **Prediction Example:**
```bash
curl -X POST "http://localhost:8000/predict" \
-H "Content-Type: application/json" \
-d '{"features": [0.5, 1.2, -0.3]}'
```

---

## **Services**

| **Service**     | **Description**                     | **URL**                   |
|------------------|-------------------------------------|---------------------------|
| **MinIO**        | Object storage                     | [https://localhost:443](https://localhost:443) |
| **MLflow**       | Experiment tracking & model store  | [http://localhost:80](http://localhost:80)     |
| **pgAdmin**      | PostgreSQL management interface    | [http://localhost:8080](http://localhost:8080) |
| **FastAPI**      | Model prediction API               | [http://localhost:8000](http://localhost:8000) |

---

## **File Structure**

```
MLOPS-PROJECT
â”‚
â”œâ”€â”€ certs/                     # Certificate generation scripts
â”œâ”€â”€ logs/                      # Log files generated by FastAPI
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for training
â”‚   â”œâ”€â”€ Example.ipynb          # Example notebook for training models
â”‚   â””â”€â”€ StressLevelDataset.csv # Sample dataset
â”œâ”€â”€ postgres/                  # PostgreSQL initialization scripts
â”œâ”€â”€ volumes/                   # Docker volumes
â”œâ”€â”€ .env                       # Environment variables (not tracked in Git)
â”œâ”€â”€ .env.example               # Example environment variables
â”œâ”€â”€ docker-compose.yaml        # Docker Compose configuration
â”œâ”€â”€ Makefile                   # Makefile for automation
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile.fastapi         # Dockerfile for FastAPI
â””â”€â”€ README.md                  # Project documentation
```

---

## **Troubleshooting**

### **1. Docker Compose Not Found**:
  Ensure Docker Compose is installed:
  ```bash
  docker compose version
  ```
  or
  ```bash
  docker-compose version
  ```
  Hereâ€™s an updated **Troubleshooting** section for your README that addresses these specific issues:

---

### **2. Permission Denied During Build**
If you encounter permission issues related to `buildx` or Docker commands, such as:
```
Permission denied
```

**Solution**: Use `sudo` when running `make`:
```bash
sudo make run
```

---

### **3. PostgreSQL Database Error**
If you see errors like:
```
PostgreSQL Database directory appears to contain a database; Skipping initialization
...
FATAL: database "auth_db" does not exist
```

This occurs because the mapped directory (`./volumes/postgres_data`) contains existing data that conflicts with the expected setup.

#### **Solution: Clear or Backup Local PostgreSQL Data**

1. **Backup the Current Data (Optional)**:
   ```bash
   tar -cvf postgres_backup.tar ./volumes/postgres_data
   ```

2. **Clear the PostgreSQL Data**:
   ```bash
   rm -rf ./volumes/postgres_data/*
   ```

3. **Reinitialize the Database**:
   ```bash
   sudo make run
   ```

   PostgreSQL will recreate the database using the `init.sql` file.

4. **Restore the Backup (If Needed)**:
   ```bash
   tar -xvf postgres_backup.tar -C ./volumes/postgres_data
   sudo make run
   ```

---

### **4. Service Logs**
To diagnose issues, always check the service logs. Run:
```bash
make logs
```

Identify specific issues with containers like `postgres`, `mlflow`, or `fastapi`. For example:
```bash
docker logs postgres
```

---

### **5. MinIO Connection Issues**
If you cannot connect to MinIO or access buckets, ensure:
1. The credentials in `.env` are correct.
2. The `dataset` bucket is created in MinIO.
3. The services are running and reachable:
   ```bash
   docker ps
   ```

Use the logs for additional debugging:
```bash
docker logs minio
```

---

### **6. Restart Services**
If issues persist, restart the services:
```bash
sudo make down
sudo make run
```

---

These troubleshooting steps should help users address common issues while setting up or running your project. Let me know if youâ€™d like further refinements!

- **Permission Issues**:
  Add your user to the `docker` group:
  ```bash
  sudo usermod -aG docker $USER
  ```

- **Connection Issues**:
  Verify the `.env` file configuration and check service logs:
  ```bash
  make logs
  ```

---

## **Contributions**

Feel free to contribute by submitting pull requests or opening issues.

---

## **Contact**

For any inquiries or issues, please contact:
ðŸ“§ contact@fauzanghaza.com

---

## **License**

This project is licensed under the MIT License.